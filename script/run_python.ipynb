{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "''' Import packages to access Weathersets when needed '''\n",
    "\n",
    "import pickle\n",
    "from weatherdata.classes import composite_dataset as Weatherset"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation over 4 files dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Select Weatherset '''\n",
    "\n",
    "wsPath = '/nird/projects/NS9873K/emile/unseen-storm-forecasts/weathersets/s2s_all-res.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "variable 'obs' is a MultiIndex, which cannot yet be serialized. Instead, either use reset_index() to convert MultiIndex levels into coordinate variables instead or use https://cf-xarray.readthedocs.io/en/latest/coding.html.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNotImplementedError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      4\u001B[39m     tpSet = pickle.load(inp)\n\u001B[32m      6\u001B[39m treatmentType = \u001B[33m\"\u001B[39m\u001B[33mmean2\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m \u001B[43mcorrelation\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhans_area_avg_correlation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtpSet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtreatmentType\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m2021-01-01\u001B[39;49m\u001B[33;43m'\u001B[39;49m\n\u001B[32m      9\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(wsPath, \u001B[33m'\u001B[39m\u001B[33mwb\u001B[39m\u001B[33m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m outp:\n\u001B[32m     12\u001B[39m     pickle.dump(tpSet, outp, pickle.HIGHEST_PROTOCOL)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/nird/projects/NS9873K/emile/unseen-storm-forecasts/script/correlation.py:211\u001B[39m, in \u001B[36mhans_area_avg_correlation\u001B[39m\u001B[34m(tpSet, treatmentType, lastDate)\u001B[39m\n\u001B[32m    208\u001B[39m name = \u001B[33m'\u001B[39m\u001B[33ms2s-HA_avg-\u001B[39m\u001B[33m'\u001B[39m+resolution+\u001B[33m'\u001B[39m\u001B[33m-ensemble_correlation-\u001B[39m\u001B[33m'\u001B[39m+treatmentType\n\u001B[32m    209\u001B[39m path = storingDir + name + \u001B[33m'\u001B[39m\u001B[33m.nc\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m211\u001B[39m \u001B[43mensemble_corr\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_netcdf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    212\u001B[39m tpSet.compute[name] = path\n\u001B[32m    214\u001B[39m \u001B[38;5;28;01mdel\u001B[39;00m ensemble_corr\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/nird/projects/NS9873K/emile/miniforge3/envs/unseen/lib/python3.13/site-packages/xarray/core/dataarray.py:4204\u001B[39m, in \u001B[36mDataArray.to_netcdf\u001B[39m\u001B[34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf, auto_complex)\u001B[39m\n\u001B[32m   4200\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   4201\u001B[39m     \u001B[38;5;66;03m# No problems with the name - so we're fine!\u001B[39;00m\n\u001B[32m   4202\u001B[39m     dataset = \u001B[38;5;28mself\u001B[39m.to_dataset()\n\u001B[32m-> \u001B[39m\u001B[32m4204\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mto_netcdf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[return-value]  # mypy cannot resolve the overloads:(\u001B[39;49;00m\n\u001B[32m   4205\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4206\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4207\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4208\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   4209\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4210\u001B[39m \u001B[43m    \u001B[49m\u001B[43mengine\u001B[49m\u001B[43m=\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4211\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4212\u001B[39m \u001B[43m    \u001B[49m\u001B[43munlimited_dims\u001B[49m\u001B[43m=\u001B[49m\u001B[43munlimited_dims\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4213\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompute\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcompute\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4214\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmultifile\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   4215\u001B[39m \u001B[43m    \u001B[49m\u001B[43minvalid_netcdf\u001B[49m\u001B[43m=\u001B[49m\u001B[43minvalid_netcdf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4216\u001B[39m \u001B[43m    \u001B[49m\u001B[43mauto_complex\u001B[49m\u001B[43m=\u001B[49m\u001B[43mauto_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4217\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/nird/projects/NS9873K/emile/miniforge3/envs/unseen/lib/python3.13/site-packages/xarray/backends/api.py:1928\u001B[39m, in \u001B[36mto_netcdf\u001B[39m\u001B[34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf, auto_complex)\u001B[39m\n\u001B[32m   1923\u001B[39m \u001B[38;5;66;03m# TODO: figure out how to refactor this logic (here and in save_mfdataset)\u001B[39;00m\n\u001B[32m   1924\u001B[39m \u001B[38;5;66;03m# to avoid this mess of conditionals\u001B[39;00m\n\u001B[32m   1925\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1926\u001B[39m     \u001B[38;5;66;03m# TODO: allow this work (setting up the file for writing array data)\u001B[39;00m\n\u001B[32m   1927\u001B[39m     \u001B[38;5;66;03m# to be parallelized with dask\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1928\u001B[39m     \u001B[43mdump_to_store\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1929\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwriter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43munlimited_dims\u001B[49m\u001B[43m=\u001B[49m\u001B[43munlimited_dims\u001B[49m\n\u001B[32m   1930\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1931\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m autoclose:\n\u001B[32m   1932\u001B[39m         store.close()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/nird/projects/NS9873K/emile/miniforge3/envs/unseen/lib/python3.13/site-packages/xarray/backends/api.py:1975\u001B[39m, in \u001B[36mdump_to_store\u001B[39m\u001B[34m(dataset, store, writer, encoder, encoding, unlimited_dims)\u001B[39m\n\u001B[32m   1972\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m encoder:\n\u001B[32m   1973\u001B[39m     variables, attrs = encoder(variables, attrs)\n\u001B[32m-> \u001B[39m\u001B[32m1975\u001B[39m \u001B[43mstore\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstore\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvariables\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_encoding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwriter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43munlimited_dims\u001B[49m\u001B[43m=\u001B[49m\u001B[43munlimited_dims\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/nird/projects/NS9873K/emile/miniforge3/envs/unseen/lib/python3.13/site-packages/xarray/backends/common.py:454\u001B[39m, in \u001B[36mAbstractWritableDataStore.store\u001B[39m\u001B[34m(self, variables, attributes, check_encoding_set, writer, unlimited_dims)\u001B[39m\n\u001B[32m    451\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m writer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    452\u001B[39m     writer = ArrayWriter()\n\u001B[32m--> \u001B[39m\u001B[32m454\u001B[39m variables, attributes = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvariables\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattributes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    456\u001B[39m \u001B[38;5;28mself\u001B[39m.set_attributes(attributes)\n\u001B[32m    457\u001B[39m \u001B[38;5;28mself\u001B[39m.set_dimensions(variables, unlimited_dims=unlimited_dims)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/nird/projects/NS9873K/emile/miniforge3/envs/unseen/lib/python3.13/site-packages/xarray/backends/common.py:638\u001B[39m, in \u001B[36mWritableCFDataStore.encode\u001B[39m\u001B[34m(self, variables, attributes)\u001B[39m\n\u001B[32m    635\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mencode\u001B[39m(\u001B[38;5;28mself\u001B[39m, variables, attributes):\n\u001B[32m    636\u001B[39m     \u001B[38;5;66;03m# All NetCDF files get CF encoded by default, without this attempting\u001B[39;00m\n\u001B[32m    637\u001B[39m     \u001B[38;5;66;03m# to write times, for example, would fail.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m638\u001B[39m     variables, attributes = \u001B[43mcf_encoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvariables\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattributes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    639\u001B[39m     variables = {\n\u001B[32m    640\u001B[39m         k: ensure_dtype_not_object(v, name=k) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m variables.items()\n\u001B[32m    641\u001B[39m     }\n\u001B[32m    642\u001B[39m     variables = {k: \u001B[38;5;28mself\u001B[39m.encode_variable(v) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m variables.items()}\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/nird/projects/NS9873K/emile/miniforge3/envs/unseen/lib/python3.13/site-packages/xarray/conventions.py:784\u001B[39m, in \u001B[36mcf_encoder\u001B[39m\u001B[34m(variables, attributes)\u001B[39m\n\u001B[32m    781\u001B[39m \u001B[38;5;66;03m# add encoding for time bounds variables if present.\u001B[39;00m\n\u001B[32m    782\u001B[39m _update_bounds_encoding(variables)\n\u001B[32m--> \u001B[39m\u001B[32m784\u001B[39m new_vars = {k: \u001B[43mencode_cf_variable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m=\u001B[49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m variables.items()}\n\u001B[32m    786\u001B[39m \u001B[38;5;66;03m# Remove attrs from bounds variables (issue #2921)\u001B[39;00m\n\u001B[32m    787\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m var \u001B[38;5;129;01min\u001B[39;00m new_vars.values():\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/nird/projects/NS9873K/emile/miniforge3/envs/unseen/lib/python3.13/site-packages/xarray/conventions.py:90\u001B[39m, in \u001B[36mencode_cf_variable\u001B[39m\u001B[34m(var, needs_copy, name)\u001B[39m\n\u001B[32m     68\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mencode_cf_variable\u001B[39m(\n\u001B[32m     69\u001B[39m     var: Variable, needs_copy: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mTrue\u001B[39;00m, name: T_Name = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m     70\u001B[39m ) -> Variable:\n\u001B[32m     71\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     72\u001B[39m \u001B[33;03m    Converts a Variable into a Variable which follows some\u001B[39;00m\n\u001B[32m     73\u001B[39m \u001B[33;03m    of the CF conventions:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     88\u001B[39m \u001B[33;03m        A variable which has been encoded as described above.\u001B[39;00m\n\u001B[32m     89\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m90\u001B[39m     \u001B[43mensure_not_multiindex\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m=\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     92\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m coder \u001B[38;5;129;01min\u001B[39;00m [\n\u001B[32m     93\u001B[39m         CFDatetimeCoder(),\n\u001B[32m     94\u001B[39m         CFTimedeltaCoder(),\n\u001B[32m   (...)\u001B[39m\u001B[32m    100\u001B[39m         variables.BooleanCoder(),\n\u001B[32m    101\u001B[39m     ]:\n\u001B[32m    102\u001B[39m         var = coder.encode(var, name=name)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/nird/projects/NS9873K/emile/miniforge3/envs/unseen/lib/python3.13/site-packages/xarray/conventions.py:60\u001B[39m, in \u001B[36mensure_not_multiindex\u001B[39m\u001B[34m(var, name)\u001B[39m\n\u001B[32m     58\u001B[39m     name = var.name\n\u001B[32m     59\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m var.dims == (name,):\n\u001B[32m---> \u001B[39m\u001B[32m60\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[32m     61\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mvariable \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[33m is a MultiIndex, which cannot yet be \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     62\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mserialized. Instead, either use reset_index() \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     63\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mto convert MultiIndex levels into coordinate variables instead \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     64\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mor use https://cf-xarray.readthedocs.io/en/latest/coding.html.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     65\u001B[39m     )\n",
      "\u001B[31mNotImplementedError\u001B[39m: variable 'obs' is a MultiIndex, which cannot yet be serialized. Instead, either use reset_index() to convert MultiIndex levels into coordinate variables instead or use https://cf-xarray.readthedocs.io/en/latest/coding.html."
     ]
    }
   ],
   "source": [
    "''' mean2 correlation '''\n",
    "\n",
    "with open(wsPath, 'rb') as inp:\n",
    "    tpSet = pickle.load(inp)\n",
    "\n",
    "treatmentType = \"mean2\"\n",
    "correlation.hans_area_avg_correlation(\n",
    "    tpSet, treatmentType, '2021-01-01'\n",
    ")\n",
    "\n",
    "with open(wsPath, 'wb') as outp:\n",
    "    pickle.dump(tpSet, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' mean3 correlation '''\n",
    "\n",
    "with open(wsPath, 'rb') as inp:\n",
    "    tpSet = pickle.load(inp)\n",
    "\n",
    "treatmentType = \"mean3\"\n",
    "correlation.hans_area_avg_correlation(\n",
    "    tpSet, treatmentType, '2021-01-01'\n",
    ")\n",
    "\n",
    "with open(wsPath, 'wb') as outp:\n",
    "    pickle.dump(tpSet, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.13 ('unseen')",
   "language": "python",
   "name": "unseen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
